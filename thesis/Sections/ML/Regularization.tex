\section{Regularization}
In \ac{ML}, overfitting occurs when a model becomes overly tuned to the training data and as a consequence 
fails to extract trends which would allow it to predict previously unseen data. The architecture of a \ac{NN}, 
the maximum depth of a boosted-\ac{DT} or even the size of the dataset can all contribute to overfitting. In the 
case of deep learning especially, overfitting can be a large problem and is therefore of focus in this thesis. Apart 
from predicting on a new data set, there are no rigid methods to detect overfitting. Instead, there exists many 
attempts to minimize the risk of it, we call these methods' \emph{regularization}. In \ac{ML}, regularization 
is known as any attempt to reduce the error in a prediction by reducing overfitting. Generally one can categorize
regularization as being either implicit or explicit. Explicit regularization means adding terms to the optimization 
problem. This is a very direct way of insuring no part of the model becomes overly dominant. Examples of this 
could be adding a penalty in the cost function of a \ac{NN} to ensure no weights become to large. Implicit
regularization is a less direct attempt of hindering overfitting. This could be changing the depth of the \ac{ML}-model,
varying the cost function or altering the data itself.
\\
A simple implicit regularization method is to introduce \emph{early stopping} in the training pipeline. Early stopping simply 
means to stop training before the parameters of the model are allowed to over tune. The usual approach 
is to introduce a goal for the training, which when reached, ends the training. Examples of these goals could be a 
predetermined loss value on the training set or training until lack of progress on a second unseen dataset. The latter
approach is the one I will use in this thesis. 
