\section{Data Preprocessing and Preselection Cuts}\label{subsec:Cuts}
To allow for deep learning and a thorough analysis one must try to keep
as much of the data as possible. At the same time, including large amounts
of irrelevant data, can be both redundant and destructive\footnote{By including 
large amounts of irrelevant data, you risk the \ac{ML} model tuning unnecessarily 
to remove easily reducible background, which could compromise performance.}. 
Therefore, preprocessing in the form of preselection cuts are necessary. 
The cuts applied in the analysis were grouped in two definitions, baseline and signal. 
The baseline requirements are written in table \ref{table:BL} and the signal requirements are written 
in table \ref{table:SG}. Both sets of requirements were inspired from the \ac{ATLAS} article from 2022 \cite{franchini_search_2019}.
Given the definitions we demand that each event contains exactly three signal (\ref{table:SG}) and 
three baseline leptons (\ref{table:BL}), thereby removing any event with more or fewer leptons. 
\\
Leptons are identified in the detector by using a likelihood-based method combining
information from different parts of the detector. The criteria of Loose or Tight 
identification are simply different thresholds in the discriminant, where Loose is 
defined with a lower threshold than Tight \cite{Aaboud_2019}. The overlap removal is used to solve any cases
where the same lepton has been reconstructed as both a muon and an electron, and leptons reconstructed 
as jets (or vice versa). The boolean of $lepPassOr$ simply applies a set of requirements to avoid any double 
counting. The cut for the longitudinal track parameters, $z_0$ is applied to ensure that the leptons originate 
from the primary vertex.
\\
As for the requirements for the signal leptons, we impose additional selections in addition 
to the baseline requirements. We require Loose isolation for both electrons and muons. This means
imposing criteria on the activity (i.e. additional tracks and deposits in the calorimeters) in a cone around the lepton. 
This is used to suppress \ac{QCD}-background events and reduce fake leptons. Similarly to the $z_0$-cut, the transverse 
track parameter is also used to ensure origin from primary vertex. A similar process was applied to jets, where the baseline 
and signal requirements are included in table \ref{table:JetCuts}, in appendix \ref{subsec:sigJets}.
\begin{figure}[H]
    \renewcommand\figurename{Table}
    \centering
    \footnotesize
    \makebox[\linewidth][c]{
        \begin{subfigure}{.475\textwidth}
            $
            \begin{array}{ccc}
                \hline \text { Requirement } & \text { Baseline electrons } & \text { Baseline muons } \\
                \hline\text{Identification} & - & \text{Loose} \\
                \text { Overlap Removal } & \text{lepPassOR} & \text{lepPassOR} \\
                \eta-\text { cut } & |\eta|<2.47 & |\eta|<2.7  \\
                \left|z_0 \sin (\theta)\right| \text { cut } & \left|z_0 \sin (\theta)\right|<0.5 \mathrm{~mm} & \left|z_0 \sin (\theta)\right|<0.5 \mathrm{~mm} \\
                \hline
            \end{array}
            $
            \caption{}
            \label{table:BL}
        \end{subfigure}
        \hspace{1.cm}
        \begin{subfigure}{.475\textwidth}
            $
            \begin{array}{ccc}
                \hline \text { Requirement } & \text { Signal electrons } & \text { Signal muons } \\
                \hline\text{Baseline} & \text{yes} & \text{yes} \\
                \text{Identification} & \text{Tight} & - \\
                \text{Isolation} & \text{LooseVarRad} & \text{LooseVarRad}  \\
                \left|d_0\right| / \sigma_{d_0} \text { cut } & \left|d_0\right| / \sigma_{d_0}<5.0 & \left|d_0\right| / \sigma_{d_0}<3.0 \\
                \hline
            \end{array}
            $
            \caption{}
            \label{table:SG}
        \end{subfigure}
        
    }
    \caption{Two tables displaying the baseline \ref{table:BL} and signal \ref{table:SG} requirements applied 
    to the data as part of the preprocessing.}
\end{figure}
As mentioned in previous sections, one must ensure a good comparison between \ac{MC}- and real data. Often one finds large 
deviation between the two in the case of either very large or very small transverse momentum, $p_T$. The latter case can 
often be caused by poor modelling of the physics at the event generator level. These are issues we aim to solve by checking
different triggers. 
\\
The triggers used in the data set were dielectron and dimuon triggers taken from previous \ac{ATLAS} publications 
\cite{atlas_collaboration_performance_2017, atlas_collaboration_performance_muons, atlas_collaboration_photons}.
Unfortunately, in the earlier parts of the analysis, I discovered that the data set I was given, did not contain the correct information 
regarding the triggers. After spending some time trying to compensate for this, my supervisor (Eirik Gramstad) suggested an alternative.
Instead of filtering using the triggers, an additional criterion of at least two leptons containing $p_T>20$GeV was placed on the data.
The criteria ensure that the momentum of the leptons are above the threshold of the triggers
% Given our data set is composed of different data sets spread over
% several years, different triggers are used. 
% \begin{table}
%     \centering
%     $
%     \begin{array}{ccc}
%         \hline \text { 2015 } & \text { 2016 } & \text { 2017 + 2018 } \\
%         \hline
%         \text{HLT\_2e12\_lhloose\_L12EM10VH} & \text{HLT\_2e17\_lhvloose\_nod0} & \text{HLT\_2e17\_lhvloose\_nod0\_L12EM15VHI} \\
%         \text{HLT\_e17\_lhloose\_mu14} & \text{HLT\_e17\_lhloose\_nod0\_mu14} & \text{HLT\_e17\_lhloose\_nod0\_mu14} \\
%         \text{HLT\_mu18\_mu8noL1} & \text{HLT\_mu22\_mu8noL1} & \text{HLT\_mu22\_mu8noL1} \\
%         & & \text{ HLT\_2e24\_lhvloose\_nod0}\\

%         \hline
%     \end{array}
%     $
%     \caption{Trigger requirments for events produced in their respective years.}
% \label{table:Triggers}
% \end{table}
