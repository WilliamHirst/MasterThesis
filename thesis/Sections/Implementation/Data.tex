\section{Tools and Data}
Every year technology for generating and measuring particle collisions is improved. 
As a consequence, the amount of data increases drastically. The ATLAS experiment
is one of the largest particle detector experiments currently operating at the 
CERN laboratory near Geneva. ATLAS alone generates approximately 1 petabyte of raw
data every second from proton proton collisions at the \ac{LHC}. 
With amounts of data this large, datahandling and storing is a big challenge. 
Therefore, taking advantage of sofisticated numerical tools and data frameworks is
pivotal if scientific development is to keep up with technological development.
\\
In this section I will cover some of the tools and framewroks I have used to 
complete my analysis. Large amounts of details and explanations will not be covered. 
Instead this section will highlight which tools were used and some of the motivation
for choosing them. Additionally I will cover some of the details regarding the data
being used, both \ac{MC} and real.
\subsection{Monte Carlo Data}
\subsection{NTuples and RDataframe}
\subsection{Root}