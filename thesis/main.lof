\acswitchoff 
\babel@toc {UKenglish}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Event Cross Section in a computer generated image of the \acs {ATLAS} detector.}}{7}{figure.caption.8}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces An illustration of the general kinematics in a particle-collision.}}{8}{figure.caption.9}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces The Feynman diagram of the signal producing a chargino-neutralino pair.\relax }}{8}{figure.caption.10}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces Feynman diagrams of background processes.}}{11}{figure.caption.11}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The value distribution of the two leading \acs {PCA}-features.}}{17}{figure.caption.12}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces The value distribution of the two last \acs {PCA}-features.}}{18}{figure.caption.13}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces An illustration of the architecture of a \acs {NN} with two hidden layers.\relax }}{19}{figure.caption.14}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces An illustration of a forward propagation from one layer to a node in the next.\relax }}{20}{figure.caption.15}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces An illustration of a Neural network with two hidden layers using the maxout layer.}}{23}{figure.caption.16}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces An illustration of three different layers, channelout, \acs {SCO} and maxout.}}{24}{figure.caption.17}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces An illustration of a comparison between the parameter individualistic network approach and the \acs {PNN}.\relax }}{25}{figure.caption.18}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces An illustration of a simple \acs {DT}, mapping a four dimensional input ($x_1,x_2,x_3,x_4$) to one of three values in the target space ($y_1,y_2,y_3$), through a set of cuts $\{c_1, c_2,c_{3}\}$.\relax }}{26}{figure.caption.19}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces An illustration of a traditional \acs {CC} approach and how non-overlapping features lead to effective signal regions.}}{27}{figure.caption.20}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces An illustration of a \acs {ROC} curve and how a random, good and perfect classifier would differ.\relax }}{28}{figure.caption.21}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces An illustration of a Gaussian distribution and the area under the curve defined by a significance equal to 1.64.\relax }}{29}{figure.caption.22}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces A depiction of all mass combinations and their respective event count in the full signal data set. Additionally, a white corner has been added to all combinations which define the original signal set.\relax }}{32}{figure.caption.23}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces A visual summary of the workflow and frameworks used in the computational analysis. \relax }}{33}{figure.caption.24}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Two tables displaying the baseline \ref {table:BL} and signal \ref {table:SG} requirements applied to the data as part of the preprocessing.\relax }}{36}{figure.caption.25}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces References to figures for all lepton (\ref {table:Ref3L}) and event (\ref {table:RefGen}) specific feature distribution which can be found in appendix \ref {subsec:Dist}.\relax }}{36}{figure.caption.26}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces \acs {MC} simulated and measured data comparison showing the $p_T$ and $\eta $ of the leading lepton as well as the $E_T^{miss}$ and flavor combination from each event.}}{37}{figure.caption.27}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces A visual summary of the network architectures used in this analysis, for the ordinary dense \acs {NN}(top), the \acs {PNN}(middle) and the maxout model(bottom).\relax }}{38}{figure.caption.28}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces The event distributions of the leading lepton for the features $P_t$ and $\phi $, for events with negative weights and all events.}}{43}{figure.caption.29}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces A grid displaying the expected significance on the original signal set, using the signal region created by the \emph {XGBoost} network.\relax }}{46}{figure.caption.30}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces The output distribution from a trained XGBoost model for the background and signals with 4 different mass combination.}}{46}{figure.caption.31}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Two grids displaying the expected significance on the original signal set, using the signal region created by two dense \acs {NN}, one with 20 nodes per hidden layer \ref {fig:NNshallowGridSig} and one with 600 \ref {fig:NNGridSig}.\relax }}{47}{figure.caption.32}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Two grids displaying the expected significance on a subset of the full signal set using the signal region created by two dense \acs {NN}'s, each training on different amounts of signal.}}{48}{figure.caption.33}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces The comparison of the training history of two \acs {NN}s, each training on different amounts of signal.}}{49}{figure.caption.34}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces A grid displaying the expected significance on a subset of the full signal set using the signal region created by a dense \acs {NN} which has trained on one mass, and has been allowed to train for 16 epochs.}}{49}{figure.caption.35}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces A calculated visualization of the activation of a three layer maxout network, before and after training.}}{50}{figure.caption.36}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces A calculated visualization of the activation of a three layer maxout network, after training and displaying the signal and background separately.}}{51}{figure.caption.37}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces A calculated visualization of the activation of a three layer maxout network, after training and displaying the results for two signal with each their own mass combination.}}{51}{figure.caption.38}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces A calculated visualization of the activation of a three layer maxout network, after training and displaying the the results for two signal with each their own mass combination, highlighting the difference between two specific nodes.}}{52}{figure.caption.39}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces A calculated visualization of the activation of a three layer \acs {SCO} network, after training and displaying the signal and background separately.}}{52}{figure.caption.40}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces A plot comparing the \acs {AUC} score made after each epoch on both the training and validation set, between a dense \acs {NN} and maxout model.}}{53}{figure.caption.41}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces A grid displaying the expected significance on the original signal set using the signal region created by the maxout network.\relax }}{54}{figure.caption.42}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces A sensitivity comparison between the ensemble networks (maxout, \acs {SCO}, channel-Out) on the original signal data.}}{55}{figure.caption.43}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces The output distribution from a trained \acs {PNN} model for the background and signals with four different mass combinations, where all events are given the same parameter.}}{56}{figure.caption.44}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces The output distribution from a trained \acs {PNN} model for the background and signals with four different mass combinations, where all events are given the same parameter.}}{56}{figure.caption.45}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces A grid displaying the expected significance on the original signal set using the signal region created by the \acs {PNN} network.\relax }}{57}{figure.caption.47}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces A sensitivity comparison between a dense \acs {NN}, \acs {PNN}, maxout and XGBoost on the original signal data.}}{59}{figure.caption.48}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Two 'pie-plots 'comparing the sensitivity on the original signal set, where each figure shows the comparison between a model (maxout and \acs {PNN}) training on data with and without a \acs {PCA}.}}{59}{figure.caption.49}%
\contentsline {figure}{\numberline {4.20}{\ignorespaces A sensitivity comparison between a dense \acs {NN}, \acs {PNN} and maxout on the original signal grid. A \acs {PCA} analysis has been applied to the data being utilized in this result.}}{60}{figure.caption.50}%
\contentsline {figure}{\numberline {4.21}{\ignorespaces A grid displaying the expected significance on the complete signal grid using the signal region created by the \acs {NN}. A band around each cell with a significance over 1.64 has been included.\relax }}{61}{figure.caption.51}%
\contentsline {figure}{\numberline {4.22}{\ignorespaces A grid displaying the expected significance on the full statistics signal set using the signal region created by the maxout network. A band around each cell with a significance over 1.64 has been included.\relax }}{62}{figure.caption.52}%
\contentsline {figure}{\numberline {4.23}{\ignorespaces A grid displaying the expected significance on the complete signal grid using the signal region created by the \acs {PNN} network. A band around each cell with a significance over 1.64 has been included.\relax }}{62}{figure.caption.53}%
\contentsline {figure}{\numberline {4.24}{\ignorespaces A sensitivity comparison between a dense \acs {NN}, \acs {PNN} and maxout on the complete signal grid. A \acs {PCA} analysis has been applied to the data being utilized by the latter two models.}}{63}{figure.caption.54}%
\contentsline {figure}{\numberline {4.25}{\ignorespaces A surface plot of the significance comparing sensitivity limits set by \acs {PNN}, dense \acs {NN}, maxout model and the \acs {ATLAS} analysis, where the models have assumed a flat uncertainty of $20\%$.}}{64}{figure.caption.55}%
\contentsline {figure}{\numberline {4.26}{\ignorespaces Two surface plots of the significance comparing sensitivity limits set by \acs {PNN}, dense \acs {NN}, maxout model and the \acs {ATLAS} analysis, where the models have assumed a flat uncertainty of $10\%$ and $<1\%$ respectively.}}{65}{figure.caption.56}%
\contentsline {figure}{\numberline {27}{\ignorespaces A grid displaying the expected significance on the original signal set using the signal region created by the \acs {SCO} \ref {fig:StochChannelOutGridSig} and a channel-out network \ref {fig:ChannelOutGridSig}.\relax }}{70}{figure.caption.59}%
\contentsline {figure}{\numberline {28}{\ignorespaces A grid displaying the expected significance on the original signal set using the signal region created by the \acs {NN} \ref {fig:NNPCAGridSig} and a maxout network \ref {fig:MaxOutPCAGridSig}. A \ac {PCA} analysis has been applied to the data being utilized in this result.\relax }}{70}{figure.caption.60}%
\contentsline {figure}{\numberline {29}{\ignorespaces A grid displaying the expected significance on the original signal set using the signal region created by the \acs {PNN} network. A \acs {PCA} analysis has been applied to the data being utilized in this result.\relax }}{71}{figure.caption.61}%
\contentsline {figure}{\numberline {30}{\ignorespaces 'Pie-plot' comparing sensitivity on the original signal set, where the figure shows the comparison between a model training on data with and without a \acs {PCA}.}}{71}{figure.caption.62}%
\contentsline {figure}{\numberline {31}{\ignorespaces 'Pie-plot' comparing sensitivity achieved by the maxout model on the original signal set, where the figure shows the comparison between a model trained on the original signal grid, and the complete signal grid.}}{72}{figure.caption.63}%
\contentsline {figure}{\numberline {32}{\ignorespaces 'Pie-plot'comparing sensitivity achieved by the \acs {PNN} model on the original signal set, where the figure shows the comparison between a model trained on the original signal grid, and the complete signal grid.}}{72}{figure.caption.64}%
\contentsline {figure}{\numberline {33}{\ignorespaces Two tables displaying the baseline \ref {table:BLJets} and signal \ref {table:SGJets} requirements of the jets applied to the data as part of the preprocessing.}}{73}{figure.caption.65}%
\contentsline {figure}{\numberline {34}{\ignorespaces \acs {MC} simulated and measured data comparison showing the $p_T$ for the first, second and third lepton. Similarly, the distribution over $\eta $ for the first, second and third lepton.}}{74}{figure.caption.66}%
\contentsline {figure}{\numberline {35}{\ignorespaces \acs {MC} simulated and measured data comparison showing the $\phi $ for the first, second and third lepton. Similarly, the distribution over $m_t$ for the first, second and third lepton.}}{75}{figure.caption.67}%
\contentsline {figure}{\numberline {36}{\ignorespaces \acs {MC} simulated and measured data comparison showing the charge for the first, second and third lepton. Similarly, the distribution over the flavor for the first, second and third lepton}}{76}{figure.caption.68}%
\contentsline {figure}{\numberline {37}{\ignorespaces \acs {MC} simulated and measured data comparison showing the $\Delta R$ \ref {fig:deltaR} and the azimuthal angle of the missing transverse energy. The distribution of the invariant mass of the three leptons and the OSSF pair. The distribution over the significance of the missing transverse energy and the sum of $P_t$.}}{77}{figure.caption.69}%
\contentsline {figure}{\numberline {38}{\ignorespaces \acs {MC} simulated and measured data comparison showing the sum of $p_T$ for the SS pair and the sum over all three leptons added with $E_t^{miss}$. The distribution of number of signal jets and the mass of the leading dijet pair. Finally, the number of B-jets with $77\%$ and $85\%$ certainty.}}{78}{figure.caption.70}%
\contentsline {figure}{\numberline {39}{\ignorespaces Contour plots of the significance achieved by the ordinary dense \acs {NN} and maxout model on the complete signal grid. Contours are drawn around the band equal to a significance of 1.64 for each model respectively (cyan) and for the \acs {ATLAS} analysis (pink).}}{82}{figure.caption.72}%
