\acswitchoff 
\babel@toc {UKenglish}{}\relax 
\setcounter {tocdepth}{1}
\contentsline {chapter}{Introduction}{1}{chapter*.4}%
\contentsline {chapter}{\numberline {1}The Standard model of elementary particles and beyond.}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}The bulding blocks}{3}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}The leptons}{4}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}The quarks}{4}{subsection.1.1.2}%
\contentsline {section}{\numberline {1.2}The Forces}{5}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Electromagnetism}{5}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}The Strong Force}{5}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}The Weak Force}{5}{subsection.1.2.3}%
\contentsline {section}{\numberline {1.3}Beyond the Standard Model}{5}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Why look beyond?}{5}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Neutrino-Mass problem}{6}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Super Symmetry and the Neutralino}{6}{subsection.1.3.3}%
\contentsline {section}{\numberline {1.4}Proton-Proton collisions at the LHC}{7}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}An Introduction to Particle Accelerators and Detecors}{7}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}The Kinematics}{7}{subsection.1.4.2}%
\contentsline {section}{\numberline {1.5}The Background Channels}{9}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Z-jets}{9}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Diboson (lll)}{9}{subsection.1.5.2}%
\contentsline {subsection}{\numberline {1.5.3}$t\bar {t}$}{9}{subsection.1.5.3}%
\contentsline {subsection}{\numberline {1.5.4}Diboson (llll)}{9}{subsection.1.5.4}%
\contentsline {subsection}{\numberline {1.5.5}Top Others}{9}{subsection.1.5.5}%
\contentsline {subsection}{\numberline {1.5.6}Single Top}{10}{subsection.1.5.6}%
\contentsline {subsection}{\numberline {1.5.7}Diboson (ll)}{10}{subsection.1.5.7}%
\contentsline {subsection}{\numberline {1.5.8}Triboson}{10}{subsection.1.5.8}%
\contentsline {subsection}{\numberline {1.5.9}W-jets}{10}{subsection.1.5.9}%
\contentsline {subsection}{\numberline {1.5.10}Higgs}{10}{subsection.1.5.10}%
\contentsline {section}{\numberline {1.6}The Signal}{12}{section.1.6}%
\contentsline {chapter}{\numberline {2}Introduction to Machine Learning and Data Analysis}{13}{chapter.2}%
\contentsline {section}{\numberline {2.1}Phenomenology}{13}{section.2.1}%
\contentsline {section}{\numberline {2.2}Optimization}{14}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Cost functions}{14}{subsection.2.2.1}%
\contentsline {subsubsection}{Binary Crossentropy}{14}{section*.12}%
\contentsline {subsection}{\numberline {2.2.2}Stochastic Gradient Descent and Mini-Batches}{14}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Memory, Adaptive Learning and ADAM}{15}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Hyperparameters}{15}{section.2.3}%
\contentsline {section}{\numberline {2.4}Data Handling}{15}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Scaling}{15}{subsection.2.4.1}%
\contentsline {subsubsection}{Standard Scaler}{15}{section*.13}%
\contentsline {subsection}{\numberline {2.4.2}Principal Component Analysis}{16}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Regularization}{16}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Early stopping}{18}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Ensembles}{18}{subsection.2.5.2}%
\contentsline {section}{\numberline {2.6}Neural Networks}{18}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}General structure}{18}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Feeding Forward}{19}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}Back Propagation}{19}{subsection.2.6.3}%
\contentsline {subsection}{\numberline {2.6.4}Activation functions}{21}{subsection.2.6.4}%
\contentsline {subsection}{\numberline {2.6.5}Network Ensembles, dropout and LWTA networks}{21}{subsection.2.6.5}%
\contentsline {subsection}{\numberline {2.6.6}Parametrized Neural Network}{23}{subsection.2.6.6}%
\contentsline {section}{\numberline {2.7}Decision Trees and Gradient Boosting}{24}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Decision Trees}{24}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Gradient Boosting in Decision Trees}{25}{subsection.2.7.2}%
\contentsline {section}{\numberline {2.8}Machine Learning Applied to a BSM Search}{26}{section.2.8}%
\contentsline {subsection}{\numberline {2.8.1}The Traditional Approach}{26}{subsection.2.8.1}%
\contentsline {subsection}{\numberline {2.8.2}The Machine Learning Approach}{26}{subsection.2.8.2}%
\contentsline {section}{\numberline {2.9}Model assessment}{27}{section.2.9}%
\contentsline {subsection}{\numberline {2.9.1}The Rate of True-Positve - ROC Curve}{27}{subsection.2.9.1}%
\contentsline {subsection}{\numberline {2.9.2}Statistical Assessment - Discovery $\&$ Exclusion}{28}{subsection.2.9.2}%
\contentsline {chapter}{\numberline {3}Implementation of the Analysis}{29}{chapter.3}%
\contentsline {section}{\numberline {3.1}Tools and Data}{29}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Monte Carlo Data}{29}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}ROOT, RDataframe and Pandas}{29}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}Computing features in ROOT: Example}{30}{subsection.3.1.3}%
\contentsline {subsection}{\numberline {3.1.4}The Signal}{31}{subsection.3.1.4}%
\contentsline {section}{\numberline {3.2}Features}{32}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Cuts and triggers}{32}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Lepton Variables}{33}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Jet Variables}{33}{subsection.3.2.3}%
\contentsline {subsection}{\numberline {3.2.4}Validation}{34}{subsection.3.2.4}%
\contentsline {subsection}{\numberline {3.2.5}Negative Weights}{35}{subsection.3.2.5}%
\contentsline {section}{\numberline {3.3}The Machine Learning Models}{37}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Model selection}{37}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Creating custom layers}{37}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Model Architecture}{38}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}Model Training and Validation}{40}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Training and Validating data}{40}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Training Strategy}{41}{subsection.3.4.2}%
\contentsline {chapter}{\numberline {4}Results \& Discussion}{43}{chapter.4}%
\contentsline {section}{\numberline {4.1}Benchmarking the Analysis with Boosted Trees}{43}{section.4.1}%
\contentsline {section}{\numberline {4.2}Dense Neural Networks}{43}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Deep vs Shallow}{43}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Parameter Specific Networks and Interpolation}{45}{subsection.4.2.2}%
\contentsline {section}{\numberline {4.3}Ensemble methods}{46}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Visualizing Sparse Pathways}{46}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Training History and Overfitting}{48}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}Comparing achieved Sensitivity between Ensemble methods}{51}{subsection.4.3.3}%
\contentsline {section}{\numberline {4.4}Parametrized Neural Network}{52}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Discriminating Masses}{52}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Sensitivity Result}{54}{subsection.4.4.2}%
\contentsline {section}{\numberline {4.5}Comparing Models on Original Signal Set}{55}{section.4.5}%
\contentsline {section}{\numberline {4.6}Increasing Sensitivity through PCA}{55}{section.4.6}%
\contentsline {section}{\numberline {4.7}Comparing Models on Full Statistics Signal}{56}{section.4.7}%
\contentsline {section}{\numberline {4.8}Comparing Exclusion Limits between ML Models and Previous Analysis}{59}{section.4.8}%
\contentsline {chapter}{Appendices}{63}{section*.70}%
\contentsline {chapter}{Appendix A}{65}{appendix*.71}%
\contentsline {section}{\numberline {A.1}Sensitivity Grids}{65}{section.Alph0.1}%
\contentsline {subsection}{\numberline {A.1.1}Ensembles}{65}{subsection.Alph0.1.1}%
\contentsline {subsection}{\numberline {A.1.2}Results from the \ac {PCA}}{65}{subsection.Alph0.1.2}%
\contentsline {section}{\numberline {A.2}The Features}{68}{section.Alph0.2}%
\contentsline {subsection}{\numberline {A.2.1}The Feature Distribution}{68}{subsection.Alph0.2.1}%
\contentsline {section}{\numberline {A.3}The implementation of Channel-Out, \ac {SCO} and Maxout}{73}{section.Alph0.3}%
